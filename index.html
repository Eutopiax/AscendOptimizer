<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AscendOptimizer: Episodic Agent for Ascend NPU Operator Optimization</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <style>
    body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }
    .author-block { margin-right: 15px; font-size: 1.1rem; }
    .publication-links { margin-top: 20px; }
    .hero-body { padding-bottom: 2rem; }
    .section { padding-top: 2rem; }
    .footnote-block { margin-right: 15px; color: #555; }
  </style>
</head>
<body>

<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <h1 class="title is-2 publication-title">AscendOptimizer: Episodic Agent for Ascend NPU Operator Optimization</h1>
      
      <div class="is-size-5 publication-authors mb-4">
        <span class="author-block"><a href="#">Jiehao Wu</a><sup>1,*</sup>,</span>
        <span class="author-block"><a href="#">Zixiao Huang</a><sup>1,*</sup>,</span>
        <span class="author-block"><a href="#">Wenhao Li</a><sup>2</sup>,</span>
        <span class="author-block"><a href="#">Junjie Sheng</a><sup>1,&dagger;</sup>,</span>
        <span class="author-block"><a href="#">Xiangfeng Wang</a><sup>3,4,&dagger;</sup></span>
      </div>

      <div class="is-size-6 publication-authors mb-4">
        <span class="author-block"><sup>1</sup>School of Computer Science and Technology, East China Normal University</span><br>
        <span class="author-block"><sup>2</sup>School of Computer Science and Technology, Tongji University</span><br>
        <span class="author-block"><sup>3</sup>Key Laboratory of Mathematics and Engineering Applications, MoE</span><br>
        <span class="author-block"><sup>4</sup>Shenzhen Loop Area Institute (SLAI)</span>
      </div>

      <div class="is-size-7 publication-authors mb-4">
        <span class="footnote-block"><sup>*</sup>Equal contribution</span>
        <span class="footnote-block"><sup>&dagger;</sup>Corresponding author</span>
      </div>

      <div class="publication-links">
        <a href="#" class="button is-dark is-rounded">
          <span class="icon"><i class="fas fa-file-pdf"></i></span>
          <span>Paper</span>
        </a>
        <a href="https://anonymous.4open.science/r/AscendOptimizer-3022/" class="button is-dark is-rounded">
          <span class="icon"><i class="fab fa-github"></i></span>
          <span>Code & Dataset</span>
        </a>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Abstract</h2>
    <div class="content has-text-justified">
      <p>
        [cite_start]AscendC operator optimization on Huawei Ascend neural processing units (NPUs) faces a two-fold knowledge bottleneck: unlike the CUDA ecosystem, there are few public reference implementations to learn from, and performance hinges on a coupled two-part artifact a host-side tiling program that orchestrates data movement and a kernel program that schedules and pipelines instructions[cite: 10].
      </p>
      <p>
        [cite_start]We present <strong>AscendOptimizer</strong>, an episodic agent that bootstraps this missing expertise by turning execution into experience[cite: 11]. [cite_start]On the host side, AscendOptimizer performs profiling-in-the-loop evolutionary search to discover valid and high-performing tiling and data-movement configurations directly from hardware feedback[cite: 12]. [cite_start]On the kernel side, it mines transferable optimization motifs by rewinding optimized kernels systematically de-optimizing them to synthesize instructive "bad-to-good" trajectories and distills these motifs into a retrievable experience bank for guided rewriting[cite: 13]. [cite_start]On a benchmark of 133 real AscendC operators, AscendOptimizer achieves a 1.34x geometric-mean speedup over the open-source baseline, with 51.88% of operators outperforming their references, outperforming strong agent and search baselines[cite: 15].
      </p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Alternating Optimization Framework</h2>
    <div class="content">
      [cite_start]<p class="has-text-centered">AscendOptimizer optimizes the host-side tiling function T and the device-side kernel code K in two stages[cite: 149]:</p>
      <ul>
        [cite_start]<li><strong>Stage I: Evolutionary-Guided Program Search.</strong> We model Tiling optimization as a program search problem, leveraging LLMs to perform evolutionary search within the function space, implicitly learning hardware constraints via Hardware-in-the-Loop (HIL) feedback[cite: 152].</li>
        [cite_start]<li><strong>Stage II: Optimization-Rewind based Experience Bootstrapping.</strong> We construct a structured optimization pattern library via "Optimization Rewind" (deliberate de-optimization), transforming infinite code search into finite expert experience retrieval and application[cite: 154].</li>
      </ul>
      <figure class="image is-centered mt-5">
        <a href="https://github.com/Eutopiax/AscendOptimizer/blob/main/framework-3.pdf" target="_blank">
          <img src="https://r.jina.ai/https://raw.githubusercontent.com/Eutopiax/AscendOptimizer/main/framework-3.png" alt="AscendOptimizer Framework" style="max-width: 100%; height: auto; border: 1px solid #ddd; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
        </a>
      </figure>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Main Performance (Ascend 910B4)</h2>
    <div class="content">
      [cite_start]<p class="has-text-centered">AscendOptimizer outperforms all baselines across every metric, reaching a GM of 1.34[cite: 245].</p>
      <table class="table is-striped is-hoverable is-fullwidth">
        <thead>
          <tr>
            <th>Category</th>
            <th>Method</th>
            <th>GM &uarr;</th>
            <th>fast 1.0 &uarr;</th>
            <th>fast 1.2 &uarr;</th>
            <th>fast 2.0 &uarr;</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Best-of-N</td>
            <td>BoN@40</td>
            <td>1.05</td>
            <td>18.05%</td>
            <td>6.77%</td>
            <td>1.50%</td>
          </tr>
          <tr>
            <td>Agent/Search</td>
            <td>OpenEvolve</td>
            <td>1.10</td>
            <td>27.07%</td>
            <td>7.52%</td>
            <td>4.51%</td>
          </tr>
          <tr class="is-selected">
            <td><strong>Ours</strong></td>
            <td><strong>AscendOptimizer</strong></td>
            <td><strong>1.34</strong></td>
            <td><strong>51.88%</strong></td>
            <td><strong>19.55%</strong></td>
            <td><strong>12.03%</strong></td>
          </tr>
        </tbody>
      </table>
      [cite_start]<p class="is-size-7 has-text-right"><em>Data sourced from Table 3 [cite: 239, 244]</em></p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">BibTeX</h2>
    <pre><code>@article{wu2026ascendoptimizer,
  title={AscendOptimizer: Episodic Agent for Ascend NPU Operator Optimization},
  author={Wu, Jiehao and Huang, Zixiao and Li, Wenhao and Sheng, Junjie and Wang, Xiangfeng},
  journal={arXiv preprint},
  year={2026}
}</code></pre>
  </div>
</section>

<footer class="footer mt-6">
  <div class="content has-text-centered">
    <p>
      Website layout inspired by InterCode and Nerfies.
    </p>
  </div>
</footer>

</body>
</html>
